---
title: 视频监控
---

## 名词解释

- DSS  数字监控系统
- IPC 网络摄像头
- NVR 最主要的功能是通过网络接收IPC（网络摄像机）设备传输的数字视频码流， 并进行存储、管理，从而实现网络化带来的分布式架构优势。

## 疑问

据孙主任所说，IBMS内是将各个系统集成在一起，防止出现事故责任分不清。

- 赛维智能是否也只是集成了大华本身提供的DSS平台，他们只是做了一个嵌入？

- 这个DSS体现在视频监控的哪里？（只在采石古镇中看到了一个截图，而体育场截图中却没有体现，所以不知道赛维智能对这两个系统的做法是否相同？还是说在体育场的视频监控系统中只有监控和录像功能，其它功能被阉割掉了？）

  

## 分析

根据孙主任发的数据库脚本，其中`video`表为视频监控相关的表，`sys_role_video`为角色摄像头表（用来做权限）。

其中`video`表中存储了所有的IPC信息，例如所属建筑，摄像头别名，是否启用，socket_address地址，IPC类型，像素等字段。



重点在于socket_address这个字段，例如`rtsp://admin:admin@172.16.31.5:554/unicast/c2/s0/`，根据大华官网文档提供的资料和可以了解到，赛维智能对视频监控使用的方法就是RTSP流媒体服务。rtsp://账号:密码@ip:port/...

这个地址是由大华的DSS平台提供RTSP流媒体服务。



果然赛维智能不采用b/s架构，毕竟从rtsp转码到rtmp再到浏览器播放就是最大的难点。

使用大华提供的demo，运行的效果图如下：

<img :src="$withBase('/others/sdk/sdk-video.jpg')">

由于我本地ip和ipc不是同一网关，因此没测试成功，登录不上去。

## 大致思路

根据 **rtsp** 提供的地址，很明显我们只需要进行拉流显示画面即可。



但是浏览器不能直接播放 **rtsp** 的视频流的，可以播放**rtmp**视频流，因此只有通过插件或者转码来实现。



目前大致有以下几种思路。



第一种就是ffmpeg+nginx+videojs。即先使用转码器**ffmpeg**将**rtsp**转成**rtmp**视频流，推流到**nginx-rtmp-module**服务，然后在浏览器拉取**nginx-rtmp-module**的**rtmp**视频流。



据说这种方法是最主流的，但是我大概看了下，`video`表中有两百多个摄像头，难道1个摄像头启动一个ffmpeg和nginx服务吗？还是说一个ffmpeg可以对多个rtsp进行转码？如果不能，那么服务器成本过高。



第二种方法是使用 websocket。但是具体没接触过，网上据说可行。



第三种方法就是使用浏览器插件，例如vlc，但是谷歌浏览器已经禁止插件了，如果使用这种方式最简单，但是局限性就是只能使用ie或者谷歌41版本以下。





##  **rtsp** ，hls 和 **rtmp** 

作为一个应用层协议，RTSP提供了一个可供扩展的框架，它的意义在于使得实时流媒体数据的受控和点播变得可能。总的说来，RTSP是一个流媒体表示 协议，主要用来控制具有实时特性的数据发送，但它本身并不传输数据，而是必须依赖于下层传输协议所提供的某些服务。RTSP可以对流媒体提供诸如播放、暂 停、快进等操作，它负责定义具体的控制消息、操作方法、状态码等，此外还描述了与RTP间的交互操作（RFC2326）。



HLS (HTTP Live Streaming)是Apple的动态码率自适应技术，主要用于PC和Apple终端的音视频服务，包括一个m3u(8)的索引文件，TS媒体分片文件和key加密串文件。HTML5直接支持这个流地址，因此只要是支持H5的设备都可以解码播放。



RTMP是Real Time Messaging Protocol（实时消息传输协议）的首字母缩写。RTMP是一种设计用来进行实时数据通信的网络协议，主要用来在Flash/AIR平台和支持RTMP协议的流媒体/交互服务器之间进行音视频和数据通信。因此在web播放过程中需要启用flash来进行对视频流的解码播放。



h5可以支持rtmp，无法播放rtsp。flash只能播放RTMP。
